# RAG_chatbot/scripts/update_hanultari.py

import os
import sys
import re
import asyncio
from dotenv import load_dotenv
from langchain_core.documents import Document
from langchain_openai import ChatOpenAI
from browser_use import Agent
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))
from RAG_chatbot.vector_store import create_vector_store

# ê²½ë¡œ ë° í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
load_dotenv()

def parse_markdown_result(result: str) -> list[Document]:
    """Agentê°€ ë°˜í™˜í•œ markdown ë¬¸ìì—´ì—ì„œ í”„ë¡œê·¸ë¨ ì •ë³´ë¥¼ íŒŒì‹±í•´ Document ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    program_blocks = re.split(r"\n\d+\.\s+\*\*Title\*\*:", result.strip())
    documents = []

    for block in program_blocks[1:]:  # ì²« ë²ˆì§¸ëŠ” ë¹ˆ ë¬¸ìì—´ì¼ ìˆ˜ ìˆìŒ
        title_match = re.search(r"^(.*?)\n", block)
        summary_match = re.search(r"\*\*Summary\*\*: (.*?)\n", block)
        location_match = re.search(r"\*\*Location\*\*: (.*?)\n", block)
        date_match = re.search(r"\*\*Date\*\*: (.*)", block)

        parts = []
        if title_match:
            parts.append("Title: " + title_match.group(1).strip())
        if summary_match:
            parts.append("Summary: " + summary_match.group(1).strip())
        if location_match:
            parts.append("Location: " + location_match.group(1).strip())
        if date_match:
            parts.append("Date: " + date_match.group(1).strip())

        if parts:
            doc = Document(page_content="\n".join(parts), metadata={"source": "hanultari"})
            documents.append(doc)

    return documents


async def fetch_hanultari_documents() -> tuple[list[Document], str]:
    """í•œìš¸íƒ€ë¦¬ ì‚¬ì´íŠ¸ì—ì„œ ë‹¤ë¬¸í™”ê°€ì¡± ì§€ì› í”„ë¡œê·¸ë¨ì„ ì¶”ì¶œí•´ Document ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
    agent = Agent(
        task="""
        Visit https://mcfamily.or.kr/ko/programs/family?page=1
        Extract only the first 10 multicultural family support programs in Korean.
        Include: title, summary, location, and date.
        Do not include HTML or unrelated information.
        """,
        llm=ChatOpenAI(
            model="deepseek/deepseek-chat:free",
            openai_api_base="https://openrouter.ai/api/v1",
            openai_api_key=os.getenv("OPENROUTER_API_KEY"),
            max_tokens=2048
        ),
    )

    result = await agent.run()

    if isinstance(result, str):
        documents = parse_markdown_result(result)
    else:
        documents = []

    return documents, result


def main():
    print("\nğŸŒ í•œìš¸íƒ€ë¦¬ ì •ì±… í¬ë¡¤ë§ ì¤‘...")
    documents, raw_result = asyncio.run(fetch_hanultari_documents())

    if not documents:
        print("\u274c í¬ë¡¤ë§ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸° â†“")
        print(raw_result)
        return

    print(f"\ud83d\udcc4 \ubb38ì„œ ìˆ˜: {len(documents)}ê°œ")

    print("\n\ud83d\udcca ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ì— ì—°ê²° ì¤‘...")
    vector_store = create_vector_store()

    print("\ud83e\udde0 \ubb38ì„œë“¤ì„ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€ ì¤‘...")
    vector_store.add_documents(documents)

    print("\u2705 í•œìš¸íƒ€ë¦¬ ì •ì±… ì •ë³´ê°€ ë²¡í„° DBì— ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")


if __name__ == "__main__":
    main()